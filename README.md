# promptoctopus README

Prompt Octopus lets you compare LLM responses in seconds. Highlight your system prompt, press ctrl+alt+j, enter user messages and images, and get a side-by-side comparison of responses from any and all LLMs.

## Features

Highlight text with Run the same prompt on multiple LLMs and compare the results.
\!\[demo video\]\(/assets/extension_demo.gif\)

Access the latest models from OpenAI, Anthropic, Deepseek, Llama, Mistral, and more :)

Enter your own API keys (stored locally, never seen by our servers) for unlimited usage. Once you enter keys, local use will be the default behavior.

Paid users get higher usage limits on Prompt Octopus servers and priority support, but everybody can ask questions at promptoctopus@gmail.com!

\!\[feature demo\]\(/assets/moon_prompt.png\)

## Requirements

If you have any requirements or dependencies, add a section describing those and how to install and configure them.

## Extension Settings

Add personal api keys by running the `promptoctopus.useLocalKeys` command (cmd/ctrl+shift+p and search "Prompt Octopus: Use Personal API Keys Locally").

## Known Issues

We're working to speed up response times for reasoning models - particularly Deepseek!

## Release Notes

### 0.1.0

Initial release!

---

## Following extension 

**Enjoy!**

---
Logo image comes from an open source project: Twemoji. The graphics are copyright 2020 Twitter, Inc and other contributors. The graphics are licensed under CC-BY 4.0.